{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6878899,"sourceType":"datasetVersion","datasetId":3952310},{"sourceId":6926110,"sourceType":"datasetVersion","datasetId":3976743}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tarfile\nimport os\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract file\nfile = tarfile.open('/kaggle/input/lfw-data/lfw-funneled.tgz')\nfile.extractall(\"/kaggle/working/\")\nfile.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview first image\nbase_image_path = \"/kaggle/working/lfw_funneled/\"\ndir_names = os.listdir(base_image_path)\nfirst_image_name = os.listdir(base_image_path + dir_names[0])\nnp_img = np.asarray(Image.open(base_image_path + dir_names[0] + \"/\" + first_image_name[0]))\nplt.imshow(np_img)\n# plt.xlabel(first_image_name[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of Candidates: {len(dir_names)}\")\ncounter = 0\nfor dir_name in dir_names:\n    try:\n        file_names = os.listdir(base_image_path + dir_name)\n        for file_name in file_names:\n            counter += 1\n    except:\n        continue\nprint(f\"Number of Files: {counter}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display RGB Image\n# fig, axs = plt.subplots(1,3,figsize=(15, 5))\n# axs[0].imshow(np_img[:,:,0], cmap='Reds')\n# axs[1].imshow(np_img[:,:,1], cmap='Greens')\n# axs[2].imshow(np_img[:,:,2], cmap='Blues')\n# axs[0].set_title(\"Red Channel\")\n# axs[1].set_title(\"Green Channel\")\n# axs[2].set_title(\"Blue Channel\")\n# plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read image using matplotlib and cv2\n# plt_img = plt.imread(base_image_path + dir_names[0] + \"/\" + first_image_name[0])\n# cv2_img = cv2.imread(base_image_path + dir_names[0] + \"/\" + first_image_name[0])\n# fig, axs = plt.subplots(1,2,figsize=(15,5))\n# axs[0].imshow(plt_img)\n# axs[1].imshow(cv2_img)\n# axs[0].set_title(\"Image from matplotlib\")\n# axs[1].set_title(\"Image from cv2\")\n# plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert BGR to RGB in cv2\n# cv2_img_rgb = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)\n# plt.imshow(cv2_img_rgb)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert Image to gray_scale\n# cv2_img_gray = cv2.cvtColor(plt_img, cv2.COLOR_RGB2GRAY)\n# plt.imshow(cv2_img_gray, cmap=\"Greys\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Resizing for image\n# cv2_img_resized = cv2.resize(plt_img, None, fx=0.50, fy=0.50)\n# plt.imshow(cv2_img_resized)\n# print(cv2_img_resized.flatten().shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply PCA for image\n# pca = PCA(n_components=15)\n# img_pca = pca.fit_transform(plt_img.mean(axis=2))\n# img_pca_projection = pca.inverse_transform(img_pca)\n# print(f\"RAW Image: {plt_img.flatten().shape}\")\n# print(f\"Image after applying PCA: {img_pca_projection.flatten().shape}\")\n# plt.imshow(img_pca_projection)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image Segmentation by K-mean Clustering for the first image with 16 colors\n# from sklearn.cluster import KMeans\n# X = np_img.reshape(-1, 3)\n# Kmeans = KMeans(n_clusters=16,n_init=10)\n# Kmeans.fit(X)\n# segmented_img = Kmeans.cluster_centers_[Kmeans.labels_]\n# segmented_img = segmented_img.reshape(np_img.shape)\n# segmented_img = segmented_img/255\n# plt.imshow(segmented_img)\n# print(f\"Image after clustered with 16 colors: {segmented_img.flatten().shape}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combined Resized and PCA\n# img_pca = pca.fit_transform(cv2_img_resized.mean(axis=2))\n# img_pca_projection = pca.inverse_transform(img_pca)\n# print(f\"RAW Image: {plt_img.flatten().shape}\")\n# print(f\"Image after applying Resized and PCA: {img_pca_projection.flatten().shape}\")\n# plt.imshow(img_pca_projection)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combined Resized, K-means clusttering 16 colors, PCA\n\n# cv2_img_resized = cv2.resize(segmented_img, None, fx=0.50, fy=0.50)\n# img_pca = pca.fit_transform(cv2_img_resized.mean(axis=2))\n# img_pca_projection = pca.inverse_transform(img_pca)\n# print(f\"RAW Image: {plt_img.flatten().shape}\")\n# print(f\"Image after applying Resized, K-means clusttering 16 colors, PCA: {img_pca_projection.flatten().shape}\")\n# plt.imshow(img_pca_projection ,cmap=\"Greys\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.histplot(plt_img.flatten())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img_cropped = plt_img[30:, 30:, :]\n# # plt.imshow(img_cropped)\n# sns.histplot(img_cropped.flatten())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# face_cascade = cv2.CascadeClassifier('/kaggle/input/haarcascade-frontalface-default/haarcascade_frontalface_default.xml')\n# gray_img = cv2.cvtColor(plt_img, cv2.COLOR_RGB2GRAY)\n# faces = face_cascade.detectMultiScale(gray_img, 1.1, 1)\n# new_img = np.zeros_like(plt_img)\n# for (x,y,w,h) in faces:\n#     img = plt_img[x:x+w, y:y+h]\n#     new_img[x:x+w, y:y+h, :] = plt_img[x:x+w, y:y+h, :]\n# plt.imshow(new_img)\n# plt.show()\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choosing Image Resize + Image Cropping + Grayscale (Exclude Image Detection)\nimages = []\ntargets = []\nface_cascade = cv2.CascadeClassifier('/kaggle/input/haarcascade-frontalface-default/haarcascade_frontalface_default.xml')\nfor dir_name in dir_names:\n    counter = 0\n    try:\n        file_names = os.listdir(base_image_path + dir_name)\n        if(len(file_names) >= 20):\n            for file_name in file_names:\n                counter = counter + 1\n#                 if counter >= 200:\n                if counter >= 300:\n                    break\n                img = plt.imread(f\"{base_image_path}{dir_name}/{file_name}\")\n#                 new_img = np.zeros_like(img)\n                try:\n#                     gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n#                     faces = face_cascade.detectMultiScale(gray_img, 1.1, 1)\n#                     for (x,y,w,h) in faces:\n#                         if len(img[x:x+w, y:y+h].flatten()) < 43200 :\n#                            break\n#                         new_img[x:x+w, y:y+h] = img[x:x+w, y:y+h]\n#                     img = new_img[60:210, 60:210]\n                    if(len(np.unique(img)) > 200):\n                        img = img[50:200, 50:200]\n#                         img = cv2.resize(img, None, fx=0.75, fy=0.75)\n                        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n                        images.append(img)\n                        targets.append(dir_name)\n                except:\n                    continue         \n    except:\n        continue\n# images = np.asarray(images)\n# targets = np.asarray(targets)\nprint(f\"Number of images: {len(images)}\")\nprint(f\"Number of identities: {len(np.unique(targets))}\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview a random image\nplt.imshow(images[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Identity Count\n\nplt.figure(figsize=(19,6))\nsns.histplot(targets)\nplt.xticks(rotation=90, fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Apply Image Augmentation\n\nimport random\nimport imgaug as ia\nimport imgaug.augmenters as iaa\n\nhflip= iaa.Fliplr(p=1.0)\nvflip= iaa.Flipud(p=1.0) \nrot = iaa.Affine(rotate=(random.randint(-180,180), random.randint(-180,180)))\n\ntarget, counts = np.unique(targets, return_counts=True)\nindentity_count = list(zip(counts, target))\nimage_with_name = list(zip(images, targets))\n\nfor ic in indentity_count:\n    if(ic[0] < 50):\n        for iwn in image_with_name:\n            if(ic[1] == iwn[1]):\n                for i in [hflip, vflip, rot]:\n                    if(i != rot):\n                        _img = i.augment_image(iwn[0])\n                        images.append(_img)\n                        targets.append(iwn[1])\n                    else:\n                        for count in range(1):\n                            _img = i.augment_image(iwn[0])\n                            images.append(_img)\n                            targets.append(iwn[1])\n    elif (ic[0] >= 50 and ic[0] < 100):\n        for iwn in image_with_name:\n            if(ic[1] == iwn[1]):\n                for i in [hflip, vflip]:\n                    _img = i.augment_image(iwn[0])\n                    images.append(_img)\n                    targets.append(iwn[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert from python list to numpy array\n\nnew_images = []\nfor image in images:\n    new_images.append(image.flatten())\nimages = np.asarray(new_images)\ntargets = np.asarray(targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check Identity Count after apply augmentation\n\nplt.figure(figsize=(19,6))\nsns.histplot(targets)\nplt.xticks(rotation=90, fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Number of images: {len(images)}\")\nprint(f\"Number of identities: {len(np.unique(targets))}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vitualize a random identity after agumentation \n\nzipped_image_00 = zip(images, targets)\ncounter = 0\nfig,axs = plt.subplots(23, 4, figsize=(30, 30))\nrow=0\ncol=0\nfor (image, target) in zipped_image_00:\n    if(target == targets[0]):\n        axs[row, col].imshow(image.reshape(150, 150))\n        col = col +1\n        if (col == 4):\n            row = row + 1\n            col = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply StandardScaler\nscaler = StandardScaler()\nimages_scaled = scaler.fit_transform(images)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply MinMaxScaler\n# from sklearn.preprocessing import MinMaxScaler\n# minmax_scaler = MinMaxScaler()\n# images_scaled = minmax_scaler.fit_transform(images_scaled)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check an image after scaled\nsns.histplot(images_scaled[0], kde=True)\n\n# Check Mean and Std after applying Standardscaler (Mean ~ 0, Standard Diviation ~ 1)\nprint(f\"Mean: {np.mean(images_scaled[0])}\")\nprint(f\"Standard Diviation: {np.std(images_scaled[0])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Principle Component Analysis with 95% of variance radio\n\npca = PCA(0.95)\nimages_pca = pca.fit_transform(images_scaled)\nprint(f\"After apply PCA: Image is in shape {images_pca.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Apply K-Mean Cluster 16-colors\n# from sklearn.cluster import KMeans\n# Kmeans = KMeans(n_clusters=16,n_init=10)\n# Kmeans.fit(X=images_pca)\n# images_segmented = Kmeans.cluster_centers_[Kmeans.labels_]\n# images_segmented.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert numpy array to pandas dataframe\n\ndf = pd.DataFrame(images_pca, targets)\ndf.reset_index(inplace=True)\ndf.rename(columns={'index':'target'}, inplace=True)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split Data to features and target\n\nX = df.drop('target', axis=1)\ny = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check the counts of each identity\n\nprint(y.value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Balance Data by using UnderSampling Random Aproach (Not Apply)\n\nfrom imblearn.under_sampling import RandomUnderSampler\nrus = RandomUnderSampler(sampling_strategy=\"not minority\")\nX_res, y_res = rus.fit_resample(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Balance Data by using OverSampling SMOTE Aproach (Applied)\n\nfrom imblearn.over_sampling import SMOTE\nsmote= SMOTE(random_state=42, sampling_strategy=\"all\")\nX_res, y_res = smote.fit_resample(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the counts of each identity after applying over sampling technique\n\nplt.figure(figsize=(19,6))\nsns.histplot(y_res)\nplt.xticks(rotation=90, fontsize=10)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Grid Search to get the best params\n\nfrom sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\nparams = {\n    'kernel':('linear', 'poly', 'rbf'),\n    'gamma': ('scale', 'auto'),\n    'class_weight': ('balanced', None),\n    'decision_function_shape': ('ovo', 'ovr')\n}\ngrid_clf = GridSearchCV(estimator=svm.SVC(),param_grid=params)\ngrid_clf.fit(X_res, y_res)\ngrid_clf.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nclf = svm.SVC(class_weight='balanced',\n decision_function_shape='ovo',\n gamma='scale',\n kernel='linear')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data to train test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_res, y_res, random_state=42, stratify=y_res, test_size=0.2)\nclf.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = clf.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply 5 folds cross_validation\nfrom sklearn.model_selection import cross_val_score\nscores = cross_val_score(clf, X_res, y_res, cv=5)\nscores","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}